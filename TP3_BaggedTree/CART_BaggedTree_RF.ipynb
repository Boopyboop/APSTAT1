{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Importation des données Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Télécharger [les donnnées Spam](https://archive.ics.uci.edu/ml/datasets/spambase) depuis la plateforme UCI. Importer les données sous python, par exemple en utilisant pandas. Donner son label à chaque variable. La variable cible $Y$ qui indique la présence d'un spam est en dernière position dans la base de données. Créer deux tableaux numpy X_Spam and Y_Spam pour ce problème de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=  \"spambase/\"\n",
    "data_path = file_path + \"spambase.names\"\n",
    "features_names = pd.read_csv(data_path,delim_whitespace=True,header=None,skiprows = ### TODO ###)\n",
    "#print(features_names.values[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = file_path + \"spambase.data\"\n",
    "Spam_data = ### TODO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Spam_data.shape)\n",
    "print(Spam_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Spam_data.describe()  # le summary de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_Spam = Spam_data.values[:,0:57]\n",
    "Y_Spam = Spam_data.values[:,57]\n",
    "\n",
    "Y_Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbres décisionnels CART "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ajuster un arbre de classification sur les données Spam avec la fonction [tree.DecisionTreeClassifier()](http://scikit-learn.org/stable/modules/tree.html#classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparer les performances de l'arbre de classification pour plusieurs choix de nombre maximal de noeuds (`max_leaf_nodes=`). On effectuera 20 découpages train - test (80% - 20%) par choix de maxnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxnodes = [2,4,6,8,10,15,20,30,50,100,200,300,400,500,800]\n",
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Representer l'erreur des arbres en fonction du nombre de noeuds terminaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances sont très bonnes car le problème est assez facile mais on observe quand même l'effet du sur-apprentissage pour les arbres les plus developpés. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Représenter l'arbre de classification avec 10 noeuds (voir [ici](http://scikit-learn.org/stable/modules/tree.html#classification))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe maintenant les données Boston depuis `sckit-learn` (voir description plus bas) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_Bost = boston.data\n",
    "Y_Bost = boston.target\n",
    "print(shape(X_Bost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Séparer les données en train - test (80% - 20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Construire (sans utiliser `BaggingRegressor()`) un bagged tree avec 10 échantillons bootstrap et donner la prédiction sur l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Faire de même en utilsant cette fois directement la fonction `BaggingRegressor()` (voir [ici](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html)), avec 20 arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagTree = ### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On peut retrouver les arbres qui forment ce bagged tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bagTree.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Afficher le premier arbre de la collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Faire de même pour agréger 20 regresseurs linéaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ajuster sur les données d'apprentissage  une forêt aléatoire composées de 10 arbres avec un nombre maximal de 4 variables considérées à chaque noeud (consulter la [doc](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)). Donner la prédiction pour les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L'attribut `.estimators_` contient la structure des 10 arbres de la forêt. Calculer les prédictions pour les données de test à partir de ces 10 arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Predict_list_arbres = [tree.predict(### TODO ###) for tree in ### TODO ###]\n",
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparer l'erreur OOB et l'erreur de test pour des RF avec un nombre d'arbres entre 2 et 100 (`n_estimators=`). On demande le calcul du score OOB dans la RF avec `oob_score = True`.\n",
    "Les scores renvoyés sont des coefficient d'ajustement $R^2$ (variance expliquée / variance totale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que certaines observations ne sont jamais en OOB, en particulier lorsque la foret contient peu d'arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les scores précédents sont des coefficients $R^2$. On peut aussi estimer l'erreur quadratique de prédiction de la forêt, et là aussi de deux façons : \n",
    "- en utilisant les échantillons OOB (avec le champ `.oob_prediction_` de la forêt ajustée) ;\n",
    "- ou plus classiquement sur l'échantillon test. \n",
    "> Pour calculer l'erreur moyenne quadratique on pourra utiliser la fonction `mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > On souhaite comparer les correlations des prédictions des arbres pour les RF et pour les bagged trees (dans le cas de 10 arbres). \n",
    "- Construire la matrice 10x10 des corrélations entre les prédictions des 10 arbres de la forêt. Chaque arbre fournit un vecteur de prédictions pour les données test. Répéter 100 fois la procédure. Proposer une statistique pour la corrélation entre les prédicteurs.\n",
    "- Faire de même pour le bagged tree\n",
    "- Comparer les corrélations ainsi obtenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque `max_features` est choisi de l'ordre de 3 ou 4, la correlation est nettement plus faible entre les prédictions des arbres de la foret qu'entre les prédictions des arbres du bagged tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur par forêt aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ajuster un classifieur par forêt aléatoire sur le jeu de données SPAM en sélectionnant le paramètre `max_features` via l'erreur OOB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance des variables dans une forêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Afficher les [importances des variables](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_) pour une RF à 10 arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ecrire une fonction pour calculer l'importance par permuatation des variables en utilisant l'échantillon out of bag. Noter qu'il est possible de retrouver les échantillons out of bag de  chaque arbre à l'aide de la commande \n",
    "`_generate_unsampled_indices(tree.random_state,n_samples)` où `tree` est un arbre de la forêt et `n_samples` la taille totale de l'échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
